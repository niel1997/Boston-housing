# **预测波士顿房价**
## **第一步 导入数据**
在这个项目中，你将利用马萨诸塞州波士顿郊区的房屋信息数据训练和测试一个模型，并对模型的性能和预测能力进行测试。通过该数据训练后的好的模型可以被用来对房屋做特定预测—尤其是对房屋的价值。对于房地产经纪等人的日常工作来说，这样的预测模型被证明非常有价值。

此项目的数据集来自UCI机器学习知识库。波士顿房屋这些数据于1978年开始统计，共506个数据点，涵盖了波士顿不同郊区房屋14种特征的信息。本项目对原始数据集做了以下处理： 
- 有16个'MEDV' 值为50.0的数据点被移除。 这很可能是由于这些数据点包含遗失或看不到的值。 
- 有1个数据点的 'RM' 值为8.78. 这是一个异常值，已经被移除。 
- 对于本项目，房屋的'RM'， 'LSTAT'，'PTRATIO'以及'MEDV'特征是必要的，其余不相关特征已经被移除。 
- 'MEDV'特征的值已经过必要的数学转换，可以反映35年来市场的通货膨胀效应。

运行下面区域的代码以载入波士顿房屋数据集，以及一些此项目所需的Python库。如果成功返回数据集的大小，表示数据集已载入成功。

## **第二步 数据分析**
在项目的第一个部分，你会对波士顿房地产数据进行初步的观察并给出你的分析。通过对数据的探索来熟悉数据可以让你更好地理解和解释你的结果。

由于这个项目的最终目标是建立一个预测房屋价值的模型，我们需要将数据集分为特征(features)和目标变量(target variable)。 
- 特征 'RM'， 'LSTAT'，和 'PTRATIO'，给我们提供了每个数据点的数量相关的信息。 
- 目标变量：'MEDV'，是我们希望预测的变量。  
他们分别被存在features和prices两个变量名中。

### **编程练习1：数据计算**
你的第一个编程练习是计算有关波士顿房价的描述统计数据。我们已为你导入了numpy，你需要使用这个库来执行必要的计算。这些统计数据对于分析模型的预测结果非常重要的。 
在下面的代码中，你要做的是： 
- 计算prices中的'MEDV'的最小值、最大值、均值、中值和标准差； 
- 将运算结果储存在相应的变量中。

### **问题 1 - 特征观察**
- 'RM' 是该地区中每个房屋的平均房间数量； 
- 'LSTAT' 是指该地区有多少百分比的房东属于是低收入阶层（有工作但收入微薄）； 
- 'PTRATIO' 是该地区的中学和小学里，学生和老师的数目比（学生/老师）。

凭直觉，上述三个特征中对每一个来说，你认为增大该特征的数值，'MEDV'的值会是增大还是减小呢？每一个答案都需要你给出理由。  
**提示**：
-你预期一个'RM' 值是6的房屋跟'RM' 值是7的房屋相比，价值更高还是更低呢？
-你认为一个“LSTAT”值为15的社区（较低阶层工人的百分比）的房价会比一个“LSTAT”值为20的社区的房价高还是低？
-你是否期望一个“PTRATIO”值（学生与教师的比率）为10的社区的房价比一个“PTRATIO”值为15的社区的房价高或低？

### **问题 1 - 回答：**
-根据上方的图，可以看出RM与MSDV成正相关，LSTAT与MSDV成负相关，PTRATIO和MSDV相关性并不强
-增大RM，MSDV增大
-增大LSTAT，MSDV减小
-增大PTRATIO，MSDV变化不确定

## **第三步、建立模型**
### **编程练习2：定义衡量标准**
如果不能对模型的训练和测试的表现进行量化地评估，我们就很难衡量模型的好坏。通常我们会定义一些衡量标准，这些标准可以通过对某些误差或者拟合程度的计算来得到。在这个项目中，你将通过运算决定系数 R2 来量化模型的表现。模型的决定系数是回归分析中十分常用的统计信息，经常被当作衡量模型预测能力好坏的标准。

R<sup>2</sup> 的数值范围从0至1，表示目标变量的预测值和实际值之间的相关程度平方的百分比。一个模型的 R<sup>2</sup> 值为0还不如直接用平均值来预测效果好；而一个 R<sup>2</sup> 值为1的模型则可以对目标变量进行完美的预测。从0至1之间的数值，则表示该模型中目标变量中有百分之多少能够用特征来解释。模型也可能出现负值的 R<sup>2</sup> 这种情况下模型所做预测有时会比直接计算目标变量的平均值差很多。  
在下方代码的 performance_metric 函数中，你要实现：
使用 sklearn.metrics 中的 r2_score 来计算  y_true 和 y_predict的 R<sup>2</sup> 值，作为对其表现的评判。  
将他们的表现评分储存到 score 变量中。  

### **问题 2 - 拟合程度**
假设一个数据集有五个数据且一个模型做出下列目标变量的预测： 
运行下面的代码单元格以使用“performance_metric”函数并计算此模型的确定系数。  

-你觉得这个模型已成功地描述了目标变量的变化吗？
-如果成功，请解释为什么，如果没有，也请给出原因。

**提示：**R<sup>2</sup> 分数是指可以从自变量中预测的因变量的方差比例。 换一种说法：

R2 为0意味着因变量不能从自变量预测。
R2 为1意味着可以从自变量预测因变量。
R2 在0到1之间表示因变量可预测的程度。
R2 为0.40意味着 Y 中40％的方差可以从 X 预测。

###  **问题 2 - 回答:**  
型成功描述了目标变量的变化，R<sup>2</sup> 因为高达0.923。

### **编程练习 2: 数据分割与重排**
接下来，你需要把波士顿房屋数据集分成训练和测试两个子集。通常在这个过程中，数据也会被重排列，以消除数据集中由于顺序而产生的偏差。 
在下面的代码中，你需要:  
使用 sklearn.model_selection 中的 train_test_split， 将features和prices的数据都分成用于训练的数据子集和用于测试的数据子集。 
- 分割比例为：80%的数据用于训练，20%用于测试。  
- 选定一个数值以设定 train_test_split 中的 random_state ，这会确保结果的一致性。 

### **问题 3 - 训练及测试**
- 将数据集按一定比例分为训练用的数据集和测试用的数据集对学习算法有什么好处？  
- 如果用模型已经见过的数据，例如部分训练集数据进行测试，又有什么坏处？  
**提示：** 如果没有数据来对模型进行测试，会出现什么问题？  
### **问题 3 - 回答:**
将数据集分为训练集和测试集的好处是可以检验模型的准确率，如果用模型已经见过的数据，可能导致模型在这部分数据上表现很好，但在别的数据上表现不好。

## **第四步 分析模型的表现**
在项目的第四步，我们来看一下不同参数下，模型在训练集和验证集上的表现。此外，您将研究一个特定的算法，该算法在整个训练集上伴随一个增加参数'max_depth' ，以观察模型复杂性如何影响性能。画出模型的表现来对于分析过程十分有益，这可以让我们看到一些单看结果看不到的行为。

### **学习曲线**
下方区域内的代码会输出四幅图像，它们是一个决策树模型在不同最大深度下的表现。每一条曲线都直观得显示了随着训练数据量的增加，模型学习曲线的在训练集评分和验证集评分的变化，评分使用决定系数R<sup>2</sup>。曲线的阴影区域代表的是该曲线的不确定性（用标准差衡量）。  
运行下方区域中的代码，并利用输出的图形回答下面的问题

### **问题 4 - 学习曲线**
选择上述图像中的其中一个，并给出其最大深度。
随着训练数据量的增加，训练集曲线的评分有怎样的变化？验证集曲线呢？
如果有更多的训练数据，是否能有效提升模型的表现呢？

**提示：**学习曲线的评分是否最终会收敛到特定的值？一般来说，你拥有的数据越多，模型表现力越好。但是，如果你的训练和测试曲线以高于基准阈值的分数收敛，这是否有必要？基于训练和测试曲线已经收敛的前提下，思考添加更多训练点的优缺点。

### **问题 4 - 回答：**
随着训练数据量的增加，训练集的评分会下降，验证集的评分会提高；如果有更多的训练数据，能有效提升模型的表现，但有一个上限。

### **复杂度曲线**
下列代码内的区域会输出一幅图像，它展示了一个已经经过训练和验证的决策树模型在不同最大深度条件下的表现。这个图形将包含两条曲线，一个是训练集的变化，一个是验证集的变化。跟学习曲线相似，阴影区域代表该曲线的不确定性，模型训练和测试部分的评分都用的 performance_metric 函数。

### **问题 5 - 偏差与方差之间的权衡**
- 当模型以最大深度1训练时，模型的预测是出现很大的偏差还是出现了很大的方差？
- 当模型以最大深度10训练时，情形又如何呢？图形中的哪些特征能够支持你的结论？

**提示：** 高偏差表示欠拟合（模型过于简单），而高方差表示过拟合（模型过于复杂，以至于无法泛化）。考虑哪种模型（深度1或10）对应着上述的情况，并权衡偏差与方差。

### **问题 5 - 回答:**
- 最大深度为1时，图中的模型预测得分只有0.4，因此模型的预测出现了很大的偏差。
- 最大深度为10时，偏差和方差都不小，但是偏差优于深度为1时。
- R<sup>2</sup>越小则偏差越大，std范围越大则方差越大

### **问题 6- 最优模型的猜测**
结合问题 5 中的图，你认为最大深度是多少的模型能够最好地对未见过的数据进行预测？你得出这个答案的依据是什么？

**提示：**查看问题5上方的图表，并查看模型在不同 depth下的验证分数。随着深度的增加模型的表现力会变得更好吗？我们在什么情况下获得最佳验证分数而不会使我们的模型过度复杂？请记住，奥卡姆剃刀：“在竞争性假设中，应该选择假设最少的那一个。”

### **问题 6 - 回答:**
- 最大深度是4能够最好的进行预测。
- 依据是当最大深度为4时，偏差最小，方差和其他差不多。

## **第五步 评估模型的表现**
在项目的最后一节中，你将构建一个模型，并使用 fit_model 中的优化模型去预测客户特征集。  

### **问题 7- 网格搜索**
- 什么是网格搜索法？
- 如何用它来优化模型？

**提示：**在解释网格搜索算法时，首先要理解我们为什么使用网格搜索算法，以及我们使用它的最终目的是什么。为了使你的回答更具有说服力，你还可以给出一个模型中可以使用此方法进行优化参数的示例。

### **问题 7 - 回答：**
网格搜索法通过遍历给定的参数组合来确定最佳的参数范围；比如决策树中最大深度的选择，我们可以给出一系列的最大深度的值，比如 {'max_depth': [1,2,3,4,5]}，然后通过网格搜索确定哪个值得出的结果最优。

### **问题 8 - 交叉验证**

- 什么是K折交叉验证法（k-fold cross-validation）？
- GridSearchCV 是如何结合交叉验证来完成对最佳参数组合的选择的？
- GridSearchCV 中的'cv_results_'属性能告诉我们什么？
- 网格搜索为什么要使用K折交叉验证？K折交叉验证能够避免什么问题？

**提示：**在解释k-fold交叉验证时，一定要理解'k'是什么，和数据集是如何分成不同的部分来进行训练和测试的，以及基于'k'值运行的次数。 在考虑k-fold交叉验证如何帮助网格搜索时，你可以使用特定的数据子集来进行训练与测试有什么缺点，以及K折交叉验证是如何帮助缓解这个问题。

### **问题 8 - 回答：**
- K折交叉验证法是指将训练集拆分为 k 个子集，每次将其中一个子集用作测试集，剩下 k-1 个子集将组合起来构成训练集。接着计算所有 k 次测试的平均误差；
- GridSearchCV通过交叉验证得到每个参数组合的得分，以此确定最优的参数组合；
- GridSearchCV 中的'cv_results_'属性能告诉我们每个参数组合的得分；
- K折交叉验证能够避免过拟合。

### **编程练习 4：训练最优模型**
在这个练习中，你将需要将所学到的内容整合，使用决策树算法训练一个模型。为了得出的是一个最优模型，你需要使用网格搜索法训练模型，以找到最佳的 'max_depth' 参数。你可以把'max_depth' 参数理解为决策树算法在做出预测前，允许其对数据提出问题的数量。决策树是监督学习算法中的一种。
另外，你会发现在实现的过程中是使用ShuffleSplit()作为交叉验证的另一种形式（参见'cv_sets'变量）。虽然它不是你在问题8中描述的K-fold交叉验证方法，但它同样非常有用！下面的ShuffleSplit()实现将创建10个('n_splits')混洗集合，并且对于每个混洗集，数据的20％（'test_size'）将被用作验证集合。当您在实现代码的时候，请思考一下它与K-fold cross-validation的不同与相似之处。
对于下面代码单元格中的 fit_model 函数，您需要实现以下内容： 
- 1.定义 'regressor' 变量: 使用 sklearn.tree 中的 DecisionTreeRegressor 创建一个决策树的回归函数;
- 2.定义 'params' 变量: 为 'max_depth' 参数创造一个字典，它的值是从1至10的数组;
- 3.定义 'scoring_fnc' 变量: 使用 sklearn.metrics 中的 make_scorer 创建一个评分函数。将 ‘performance_metric’ 作为参数传至这个函数中；
- 4.定义 'grid' 变量: 使用 sklearn.model_selection 中的 GridSearchCV 创建一个网格搜索对象；将变量'regressor', 'params', 'scoring_fnc'和 'cross_validator' 作为参数传至这个对象构造函数中；

## **第六步 做出预测**

当我们用数据训练出一个模型，它现在就可用于对新的数据进行预测。在决策树回归函数中，模型已经学会对新输入的数据提问，并返回对目标变量的预测值。你可以用这个预测来获取数据未知目标变量的信息，这些数据必须是不包含在训练数据之内的。

### **问题 9 - 最优模型**
- 最优模型的最大深度（maximum depth）是多少？此答案与你在问题 6所做的猜测是否相同？

### **问题 9 - 回答：**
最优模型的最大深度（maximum depth）是4，答案是相同的。

### **问题 10 - 预测销售价格**
想像你是一个在波士顿地区的房屋经纪人，并期待使用此模型以帮助你的客户评估他们想出售的房屋。你已经从你的三个客户收集到以下的资讯:
图
- 你会建议每位客户的房屋销售的价格为多少？
- 从房屋特征的数值判断，这样的价格合理吗？为什么？
**提示：**用你在分析数据部分计算出来的统计信息来帮助你证明你的答案。
### **问题 10 - 回答：**
- 客户1的房屋售价为412,950.00 USD，这个价格合理，因为该房屋的房间数量适中，贫困阶层适中，邻近学校的学生-老师比例适中，因此价格也适中；
- 客户2的房屋售价为234,529.79 USD，这个价格合理，因为该房屋的房间数量较少，贫困阶层较多，邻近学校的学生-老师比例较大，因此价格偏低；
- 客户3的房屋售价为896,962.50 USD，这个价格合理，因为该房屋的房间数量较多，贫困阶层较少，邻近学校的学生-老师比例较小，因此价格较高。

### **敏感度**
一个最优的模型不一定是一个鲁棒模型。有的时候模型会过于复杂或者过于简单，以致于难以泛化新增添的数据；有的时候模型采用的学习算法并不适用于特定的数据结构；有的时候样本本身可能有太多噪点或样本过少，使得模型无法准确地预测目标变量。这些情况下我们会说模型是欠拟合的。

### **问题 13 - 实用性探讨**
简单地讨论一下你建构的模型能否在现实世界中使用？

**提示：**回答以下几个问题，并给出相应结论的理由：
- 1978年所采集的数据，在已考虑通货膨胀的前提下，在今天是否仍然适用？
- 数据中呈现的特征是否足够描述一个房屋？
- 在波士顿这样的大都市采集的数据，能否应用在其它乡镇地区？
- 你觉得仅仅凭房屋所在社区的环境来判断房屋价值合理吗？

### **问题 13 - 回答：**
- 1978年所采集的数据，即使考虑到通货膨胀的前提下，其价格也已经不再适用了，需要换算成现在的物价水平；
- 数据中只呈现了三个特征，这肯定不能描述一个房屋，比如交通，所在地域等因素也是影响房屋价格的特征；
- 在波士顿这样的大都市采集的数据，不能应用在其它乡镇地区，大城市跟乡镇地区的物价差异较大，特别是房子这类不动产；
- 我觉得仅仅凭房屋所在社区的环境来判断房屋价值不合理，这只是评价标准中的一个，房屋的价值是多方面的。